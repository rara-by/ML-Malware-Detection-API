{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn==1.2.1) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn==1.2.1) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn==1.2.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn==1.2.1) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-26 20:26:16--  https://storage.googleapis.com/aiec-s24/4-%20Training%20a%20Static%20Malware%20Detector.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.167.207, 172.253.62.207, 172.253.115.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.167.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 97064832 (93M) [application/x-zip-compressed]\n",
      "Saving to: ‘4- Training a Static Malware Detector.zip’\n",
      "\n",
      "100%[======================================>] 97,064,832  28.4MB/s   in 3.3s   \n",
      "\n",
      "2024-03-26 20:26:20 (28.4 MB/s) - ‘4- Training a Static Malware Detector.zip’ saved [97064832/97064832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download malware data\n",
    "!wget https://storage.googleapis.com/aiec-s24/4-%20Training%20a%20Static%20Malware%20Detector.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data directory\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip '4- Training a Static Malware Detector.zip' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directoriesWithLabels = [(\"Training a Static Malware Detector/Code/Samples/Benign\",0), \n",
    "                         (\"Training a Static Malware Detector/Code/Samples/Malware\",1)]\n",
    "listOfSamples = []\n",
    "labels = []\n",
    "for datasetPath, label in directoriesWithLabels:\n",
    "    samples = [f for f in os.listdir(datasetPath)]\n",
    "    for file in samples:\n",
    "        filePath = os.path.join(datasetPath, file)\n",
    "        listOfSamples.append(filePath)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "samples_train, samples_test, labels_train, labels_test = train_test_split(listOfSamples, labels, test_size=0.33, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  492\n",
      "Number of testing samples:  243\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples: \", len(labels_train))\n",
    "print(\"Number of testing samples: \", len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pefile in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2023.2.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import pefile\n",
    "from joblib import dump, load\n",
    "\n",
    "def readFile(filePath):\n",
    "    with open(filePath, \"rb\") as binary_file:\n",
    "        data = binary_file.read()\n",
    "    return data\n",
    "\n",
    "def byteSequenceToNgrams(byteSequence, n):\n",
    "    Ngrams = ngrams(byteSequence, n)\n",
    "    return list(Ngrams)\n",
    "    \n",
    "def extractNgramCounts(file, N):\n",
    "    fileByteSequence = readFile(file)\n",
    "    fileNgrams = byteSequenceToNgrams(fileByteSequence, N)\n",
    "    return collections.Counter(fileNgrams)\n",
    "\n",
    "def getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list):\n",
    "    K1 = len(K1_most_common_Ngrams_list)\n",
    "    fv = K1*[0]\n",
    "    fileNgrams = extractNgramCounts(file, N)\n",
    "    for i in range(K1):\n",
    "        fv[i]=fileNgrams[K1_most_common_Ngrams_list[i]]\n",
    "    return fv\n",
    "\n",
    "def preprocessImports(listOfDLLs):\n",
    "    processedListOfDLLs = []\n",
    "    temp = [x.decode().split(\".\")[0].lower() for x in listOfDLLs]\n",
    "    return \" \".join(temp)\n",
    "\n",
    "def getImports(pe):\n",
    "    listOfImports = []\n",
    "    for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "        listOfImports.append(entry.dll)\n",
    "    return preprocessImports(listOfImports)\n",
    "\n",
    "def getSectionNames(pe):\n",
    "    listOfSectionNames = []\n",
    "    for eachSection in pe.sections:\n",
    "        refined_name = eachSection.Name.decode().replace('\\x00','').lower()\n",
    "        listOfSectionNames.append(refined_name)\n",
    "    return \" \".join(listOfSectionNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2-Grams, \n",
    "# and produce feature vectors based on the frequency method\n",
    "# This may take a few minutes to run\n",
    "N=2\n",
    "totalNgramCount = collections.Counter([])\n",
    "for file in samples_train:\n",
    "    totalNgramCount += extractNgramCounts(file, N)\n",
    "K1 = 100\n",
    "K1_most_common_Ngrams = totalNgramCount.most_common(K1)\n",
    "K1_most_common_Ngrams_list = [x[0] for x in K1_most_common_Ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Static Malware Detector/Code/Samples/Benign/pmgrant.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/RegAsm.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/aspnetca.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/LogCollector.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/oisicon.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/ldifde.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/adaminstall.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/FixSqlRegistryKey_ia64.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/FixSqlRegistryKey_x64.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Malware/VirusShare_7a30183b105b4200fc201925aba4886c.exe:\n",
      "'utf-8' codec can't decode byte 0xb8 in position 0: invalid start byte\n",
      "Training a Static Malware Detector/Code/Samples/Benign/lc.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/urlproxy.exe:\n",
      "'Invalid NT Headers signature. Probably a NE file'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/evntwin.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/pmsort.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/InstallUtil.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/Common.DBConnection64.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/LockAppHost.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "# Extract N-gram features based on the frequency method\n",
    "# Also, extracts some metadata such as DLL imports, \n",
    "# and PE Sections. We will combine these with\n",
    "# our N-gram features to enrich the sample representation.\n",
    "# This will take a few minutes to run.\n",
    "# Some samples will generate errors such as 'not a PE file',\n",
    "# 'DOS header not found', and 'invalid attribute'. These are OK.\n",
    "importsCorpus_train = []\n",
    "numSections_train = []\n",
    "sectionNames_train = []\n",
    "NgramFeaturesList_train = []\n",
    "y_train = []\n",
    "for i in range(len(samples_train)):\n",
    "    file = samples_train[i]\n",
    "    try:\n",
    "        NGramFeatures = getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list)\n",
    "        pe = pefile.PE(file)\n",
    "        imports = getImports(pe)\n",
    "        nSections = len(pe.sections)\n",
    "        secNames = getSectionNames(pe)\n",
    "        importsCorpus_train.append(imports)\n",
    "        numSections_train.append(nSections)\n",
    "        sectionNames_train.append(secNames)\n",
    "        NgramFeaturesList_train.append(NGramFeatures)\n",
    "        y_train.append(labels_train[i])\n",
    "    except Exception as e: \n",
    "        print(file+\":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines, we define a pipeline of sequential transforms (HashingVectorizer and TfidfTransformer) to extract N-gram featurs and construct feature vectors from the DLL imports and Section names extracted for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_featurizer = Pipeline([('vect', HashingVectorizer(input='content', ngram_range=(1, 2))),('tfidf', TfidfTransformer(use_idf=True, )),])\n",
    "section_names_featurizer = Pipeline([('vect', HashingVectorizer(input='content', ngram_range=(1, 2))),('tfidf', TfidfTransformer(use_idf=True, )),])\n",
    "importsCorpus_train_transformed = imports_featurizer.fit_transform(importsCorpus_train)\n",
    "sectionNames_train_transformed = section_names_featurizer.fit_transform(sectionNames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the binary N-gram features with \n",
    "# the DLL imports and section names features to create\n",
    "# vectorized training samples\n",
    "X_train = hstack([NgramFeaturesList_train, importsCorpus_train_transformed,sectionNames_train_transformed, csr_matrix(numSections_train).transpose()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Random Forest classifier\n",
    "# This may take a few minutes.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=1)\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936842105263158"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Static Malware Detector/Code/Samples/Benign/malias.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/newmail.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/SettingSyncHost.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/BootExpCfg.exe:\n",
      "'DOS Header magic not found.'\n",
      "Training a Static Malware Detector/Code/Samples/Benign/fsynonym.exe:\n",
      "'Invalid e_lfanew value, probably not a PE file'\n",
      "Training a Static Malware Detector/Code/Samples/Malware/VirusShare_1a89b7d4fb8ded72e1f8e81ee9352262.exe:\n",
      "'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte\n",
      "Training a Static Malware Detector/Code/Samples/Malware/VirusShare_14f3035781bb698c37ad287483af569e.exe:\n",
      "'utf-8' codec can't decode byte 0x8d in position 0: invalid start byte\n",
      "Training a Static Malware Detector/Code/Samples/Benign/sysprep.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "# Generate feature vectors for the test samples\n",
    "# This may take a few minutes\n",
    "importsCorpus_test = []\n",
    "numSections_test = []\n",
    "sectionNames_test = []\n",
    "NgramFeaturesList_test = []\n",
    "y_test = []\n",
    "for i in range(len(samples_test)):\n",
    "    file = samples_test[i]\n",
    "    try:\n",
    "        NGramFeatures = getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list)\n",
    "        pe = pefile.PE(file)\n",
    "        imports = getImports(pe)\n",
    "        nSections = len(pe.sections)\n",
    "        secNames = getSectionNames(pe)\n",
    "        importsCorpus_test.append(imports)\n",
    "        numSections_test.append(nSections)\n",
    "        sectionNames_test.append(secNames)\n",
    "        NgramFeaturesList_test.append(NGramFeatures)\n",
    "        y_test.append(labels_test[i])\n",
    "    except Exception as e: \n",
    "        print(file+\":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "importsCorpus_test_transformed = imports_featurizer.transform(importsCorpus_test)\n",
    "sectionNames_test_transformed = section_names_featurizer.transform(sectionNames_test)\n",
    "X_test = hstack([NgramFeaturesList_test, importsCorpus_test_transformed,sectionNames_test_transformed, csr_matrix(numSections_test).transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._coo.coo_matrix"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872340425531915"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** The training and test accuracies are unusually high. Can you propose a diagnosis for these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- your response\n",
    "\n",
    "The dataset contains 435 malware samples and 300 benign samples. The unusually balanced data may be a reason for the high accuracies. Also the choice of the classifier may also have played an important role. The random forest classifier is a robust ensemble model that usually provides good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section_names_featurizer.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model and featurizers\n",
    "dump(clf, 'model.joblib') \n",
    "\n",
    "dump(imports_featurizer, 'imports_featurizer.joblib')\n",
    "dump(section_names_featurizer, 'section_names_featurizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/\n",
      "model/code/\n",
      "model/code/requirements.txt\n",
      "model/code/entrypoint.py\n",
      "model.joblib\n"
     ]
    }
   ],
   "source": [
    " !tar -czvf model.tar.gz model model.joblib --exclude '.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplified-midterm-03/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "bucket = \"simplified-midterm-03\"\n",
    "\n",
    "# s3.Bucket(\"midterm-project-malconv\").upload_file('model.tar.gz', Key='model.tar.gz')\n",
    "s3.Bucket(bucket).Object('model.tar.gz').upload_fileobj(fObj)\n",
    "print(os.path.join(bucket, 'model.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://simplified-midterm-03/model.tar.gz'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_data = \"s3://{}/{}\".format(bucket, 'model.tar.gz')\n",
    "pretrained_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2097253)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate feature vectors for the test sample\n",
    "\n",
    "importsCorpus_test = []\n",
    "numSections_test = []\n",
    "sectionNames_test = []\n",
    "NgramFeaturesList_test = []\n",
    "y_test = []\n",
    "sample_test = ['Training a Static Malware Detector/Code/Samples/Benign/file-uri.exe'] # test sample benign\n",
    "# sample_test = [samples_test[1]] # test sample malware\n",
    "\n",
    "for i in range(len(sample_test)):\n",
    "    file = sample_test[i]\n",
    "    try:\n",
    "        NGramFeatures = getNGramFeaturesFromSample(file, K1_most_common_Ngrams_list)\n",
    "        pe = pefile.PE(file)\n",
    "        imports = getImports(pe)\n",
    "        nSections = len(pe.sections)\n",
    "        secNames = getSectionNames(pe)\n",
    "        importsCorpus_test.append(imports)\n",
    "        numSections_test.append(nSections)\n",
    "        sectionNames_test.append(secNames)\n",
    "        NgramFeaturesList_test.append(NGramFeatures)\n",
    "        y_test.append(labels_test[i])\n",
    "    except Exception as e: \n",
    "        print(file+\":\")\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "imports_featurizer = load('imports_featurizer.joblib')\n",
    "section_names_featurizer = load('section_names_featurizer.joblib')\n",
    "\n",
    "importsCorpus_test_transformed = imports_featurizer.transform(importsCorpus_test)\n",
    "sectionNames_test_transformed = section_names_featurizer.transform(sectionNames_test)\n",
    "X_test_1 = hstack([NgramFeaturesList_test, importsCorpus_test_transformed,sectionNames_test_transformed, csr_matrix(numSections_test).transpose()])\n",
    "X_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "---------!"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "sklearn_model = SKLearnModel(model_data=\"s3://simplified-midterm-03/model.tar.gz\", \n",
    "                             role=role,\n",
    "                             entry_point=\"entrypoint.py\",\n",
    "                             source_dir=\"model/code/\",\n",
    "                             py_version='py3',\n",
    "                             framework_version=\"1.2-1\",\n",
    "                            dependencies=['model/code/requirements.txt'])\n",
    "\n",
    "predictor = sklearn_model.deploy(instance_type=\"ml.t2.medium\", initial_instance_count=1, \n",
    "#                                  content_type=\"application/json\",\n",
    "                                serializer=JSONSerializer(content_type= 'application/json'),  \n",
    "                                deserializer=JSONDeserializer()\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [0], 'label': 'benign'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format request\n",
    "import json\n",
    "\n",
    "data = X_test_1.data.tolist()\n",
    "row = X_test_1.row.tolist()\n",
    "col = X_test_1.col.tolist()\n",
    "shape = X_test_1.shape\n",
    "\n",
    "# Create JSON payload\n",
    "payload = {\n",
    "    \"data\": data,\n",
    "    \"row\": row,\n",
    "    \"col\": col,\n",
    "    \"shape\": shape\n",
    "}\n",
    "json_payload = json.dumps(payload)\n",
    "\n",
    "# # set predictor request/response formats\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "result = predictor.predict(json_payload)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-scikit-learn-2024-03-29-03-21-47-783'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\r\n"
     ]
    }
   ],
   "source": [
    "#local testing (for a previous version of the entrypoint script)\n",
    "!python entrypoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training a Static Malware Detector/Code/Samples/Benign/file-uri.exe'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result: {'prediction': [0], 'label': 'benign'}\r\n",
      "Label:  ['Benign']\r\n"
     ]
    }
   ],
   "source": [
    "!python pyclient.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training a Static Malware Detector/Code/Samples/Malware/VirusShare_4ff0a32af391e7438f378c4c3e962da8.exe'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result: {'prediction': [1], 'label': 'malware'}\r\n",
      "True label:  ['Malware']\r\n"
     ]
    }
   ],
   "source": [
    "!python client/pyclient.py --sample 'Training a Static Malware Detector/Code/Samples/Malware/VirusShare_4ff0a32af391e7438f378c4c3e962da8.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
